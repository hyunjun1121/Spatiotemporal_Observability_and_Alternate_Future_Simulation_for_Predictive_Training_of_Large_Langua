# Related Work Notes

## Population Based Training (PBT) — 2017_Jaderberg_PBT.pdf
- 핵심 아이디어: 여러 모델 population을 동시에 학습하며 periodic한 "exploit–explore"로 **weights + hyperparameters**를 복제/변이하여 **online**으로 schedule을 찾음.
- 활용 포인트: 우리의 "time-parallel" 개념과 대비해 **baseline**으로 설정. 동일 모델 단일 역사선에서 **branch simulation**으로 의사결정하는 본 프레임워크가 PBT 대비 **compute efficiency / stability**를 얼마나 절약·개선하는지 비교지표 제공.
- 주의/한계: PBT는 **space-parallel**이라 메모리·연산비가 큼. 또한 **short-horizon greediness** 이슈 보고됨.
- 키워드: Population Based Training, exploit–explore, online hyperparameter schedule.

## Speculative Decoding 계열
### 2022_Leviathan_SpeculativeDecoding.pdf
- 핵심 아이디어: 작은 **draft model**이 여러 토큰을 제안하면 큰 **target model**이 **verification**으로 승인/거절하여 **latency**를 줄임.
- 활용 포인트: 우리 훈련에서는 **proxy model**이 short-horizon 미래 지표를 draft처럼 **speculate**하고, 실제 훈련이 부분 검증자 역할을 함. **accept/reject** 설계를 차용해 분기 결과 신뢰도 calibration 설계.
- 키워드: draft/target, verification, throughput.

### 2023_Chen_SpeculativeSampling.pdf, 2023_Liu_OnlineSpeculativeDecoding.pdf, 2024_Yan_DecodingSpecDec.pdf
- 핵심 아이디어: **draft selection**, **online adaptation**, **throughput–accuracy trade-off 분석**. 
- 활용 포인트: proxy 선택/크기/정확도–비용 trade-off를 설계할 때 **draft-target mismatch** 이슈와 **adaptive draft** 전략을 그대로 차용.
- 키워드: speculative sampling, online speculative decoding, draft calibration.

## MuZero — 2020_Schrittwieser_MuZero_Nature.pdf
- 핵심 아이디어: 학습된 **world model**(policy/value/reward)을 이용해 **planning**(MCTS)으로 multi-step 앞을 내다봄.
- 활용 포인트: 우리의 **training dynamics proxy**가 곧 훈련의 world model. **short-horizon rollouts**와 **value-like score**(예: expected loss at +N steps, stability risk)로 branch 평가 설계.
- 키워드: model-based RL, world model, planning, MCTS.

## Learning Curve Extrapolation — 2015_Domhan_LCExtrapolation_IJCAI.pdf
- 핵심 아이디어: 초반 **learning curve**로 이후 성능을 **extrapolation**하여 **early stopping**/resource 절약.
- 활용 포인트: proxy가 직접 dynamics를 학습하기 전, **cheap predictor**로 branch 후보 pruning. 또한 proxy 학습의 **feature**로 learning curve parameters 활용.
- 키워드: learning curve extrapolation, early stopping, Bayesian/MCMC fit.

## Hypergradient Descent — 2017_Baydin_HypergradientDescent.pdf
- 핵심 아이디어: **hypergradient**로 **learning rate**를 online 업데이트.
- 활용 포인트: branch action space에 **hypergradient-informed proposals** 추가(예: LR up/down 보폭 자동 조정). 또한 proxy loss에 hypergradient term을 **feature**로 포함 가능.
- 키워드: hypergradient, online LR adaptation.

## Learning to Learn by GD by GD — 2016_Andrychowicz_L2L_byGD.pdf
- 핵심 아이디어: **optimizer** 자체를 **meta-learning**(RNN)으로 학습.
- 활용 포인트: proxy를 단순 MLP가 아닌 **meta-learned optimizer/dynamics**로 확장하는 로드맵. small-scale ablation에서 효과 검증.
- 키워드: meta-optimizer, learned optimizer.

## Activation Checkpointing — 2016_Chen_SublinearMemoryCheckpointing.pdf
- 핵심 아이디어: **rematerialization**로 **activation** 저장을 줄여 **O(√n)** memory 달성.
- 활용 포인트: 우리의 **quantum checkpointing** I/O 부담 완화. branch simulation에서 **cheap replay**를 위해 activation 저장전략/복원전략을 체계화.
- 키워드: activation checkpointing, rematerialization, memory–compute trade-off.

## RevNet — 2017_Gomez_RevNet.pdf
- 핵심 아이디어: **reversible layers**로 activation 저장 없이 역전파 가능.
- 활용 포인트: 장기적으로 **state vector** 저장량 축소(특히 activation) 설계에 참고. branch 시뮬레이션의 **state footprint**를 줄여 병렬도 향상.
- 키워드: reversible residual network, invertible layers.

## Stabilizing LLM Pre-training — 2024_Takase_StabilizingLLMPretraining.pdf
- 핵심 아이디어: **loss spike** 원인 분석(gradients/shortcuts/LN 등)과 **stability** 조건 제시.
- 활용 포인트: 우리의 **uncertainty index**에 들어갈 **gradient/activation diagnostics** 정의, **trigger**의 민감도·특이도 튜닝 기준.
- 키워드: loss spike, gradient explosion, stabilization conditions.

## SPAM — 2025_Huang_SPAM_StableLLM.pdf
- 핵심 아이디어: **momentum reset** + **spike-aware clipping**으로 **gradient spike** 대응.
- 활용 포인트: branch action 후보에 “**momentum reset**”, “**spike-aware clipping** 활성화”를 포함. 또한 **counterfactual**로 “SPAM on/off” 비교 baseline.
- 키워드: spike-aware clipping, momentum reset, stability.

## ZClip — 2025_Kumar_ZClip.pdf
- 핵심 아이디어: **z-score 기반 anomaly detection**으로 **adaptive gradient clipping** 수행, **EMA**로 통계 추적.
- 활용 포인트: 우리의 **uncertainty index** 구성 요소(gradient norm anomaly detector)로 **ZClip-style z-score**를 채용. branch action에서 **clip bound** 자동화.
- 키워드: adaptive clipping, z-score, EMA, anomaly detection.

## ARC (Adaptive Gradient Clipping) — 2025_Allouah_ARC_ICLR.pdf
- 핵심 아이디어: **adaptive clipping**을 이론적으로 분석하고 **robustness**를 보장하는 설계.
- 활용 포인트: ZClip과 함께 **adaptive clipping** 설계의 이론적 백업. proxy feature로 **per-step clip statistics**를 기록.
- 키워드: adaptive clipping, robustness, federated (개념 전이).
